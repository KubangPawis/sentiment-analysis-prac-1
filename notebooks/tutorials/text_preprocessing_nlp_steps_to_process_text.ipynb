{
  "metadata": {
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 320111,
          "sourceType": "datasetVersion",
          "datasetId": 134715
        }
      ],
      "dockerImageVersionId": 30664,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# <p style=\"font-family:newtimeroman;font-size:150%;text-align:center;color:#8b4513;\">Text Preprocessing in NLP | Basis Steps to Preprocess The Textual Data </p>\n",
        "***Text preprocessing is a crucial step in Natural Language Processing (NLP) that involves cleaning and transforming raw text data into a format suitable for analysis and machine learning models. This process is vital for enhancing the performance and accuracy of NLP tasks.***\n",
        "\n",
        "***One key reason for text preprocessing is to remove noise and irrelevant information from the text, such as special characters, punctuation, and stop words. This helps in reducing the dimensionality of the data and improves the efficiency of subsequent analysis. Additionally, text normalization techniques, such as stemming and lemmatization, ensure that words are represented in their base or root form, reducing redundancy and enhancing the consistency of the dataset.***\n",
        "\n",
        "***For example, consider the sentence: \"The quick brown foxes are jumping over the lazy dogs.\" After preprocessing, it might become: \"quick brown fox jump lazy dog.\" This simplification facilitates better feature extraction and enables NLP models to focus on the essential linguistic elements.***\n",
        "\n",
        "***Moreover, text preprocessing addresses issues like :***\n",
        "- Lowercase letters.\n",
        "- Removing HTML tags.\n",
        "- Removing URLs.\n",
        "- Removing punctuation.\n",
        "- Chat Words Treatment.\n",
        "- Spelling Correction.\n",
        "- Removing stop words\n",
        "- Handling Emojies\n",
        "- Tokenization\n",
        "- Stemming\n",
        "- Lemmatization\n",
        "\n",
        "***We Will discuss the Solutions to Handles the above mentioned Issues.***"
      ],
      "metadata": {
        "id": "SAZuh0M5thk6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](attachment:ddfa0c53-65c4-4202-ba87-48fc10d89a00.png)"
      ],
      "metadata": {
        "id": "gUevhEhNthk_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Pic Credit :  https://ayselaydin.medium.com/1-text-preprocessing-techniques-for-nlp-37544483c007***"
      ],
      "metadata": {
        "id": "BGymQKnWthlA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <p style=\"font-family:newtimeroman;font-size:150%;text-align:center;color:#8b4513;\">About the Author </p>\n",
        "##### ***Hello, I'm  Muhammad_Abdullah : A Data Science Enthusiast and Kaggle 2x Expert***\n",
        "\n",
        "Greetings! I'm delighted to welcome you into my world of data science exploration and innovation. I'm **Muhammad_Abdullah**, a passionate data scientist with a fervent dedication to unraveling the mysteries hidden within datasets and leveraging the power of machine learning to drive meaningful insights and solutions.\n",
        "\n",
        "###### ***A Passion for Data Science***\n",
        "\n",
        "Since the inception of my journey into the captivating realm of data science, I've been driven by an insatiable curiosity and an unwavering passion for uncovering the stories embedded in data. From the thrill of diving deep into complex datasets to the exhilaration of crafting predictive models that shape our understanding of the world, data science has become not just a profession but a lifelong passion.\n",
        "\n",
        "###### ***Guiding Light on Kaggle***\n",
        "\n",
        "As a Kaggle 2x Expert, I've had the privilege of sharing my knowledge, insights, and experiences with the vibrant Kaggle community. Through meticulously crafted notebooks, engaging discussions, and collaborative projects, I've had the opportunity to mentor aspiring data enthusiasts, foster a culture of learning and growth, and contribute to the collective pursuit of excellence in data science.\n",
        "\n",
        "###### ***Let's Explore Together***\n",
        "\n",
        "Join me on an exhilarating adventure into the dynamic world of data science! Together, we'll unlock the potential of data, unravel its mysteries, and embark on a transformative journey of discovery and innovation. Whether you're a seasoned data enthusiast or just beginning your data science odyssey, I'm excited to share this journey with you and explore the endless possibilities that data science has to offer.\n",
        "<div style=\"text-align: left;\">\n",
        "    <table>\n",
        "        <tr>\n",
        "            <th><b>Website</b></th>\n",
        "            <th><b>Links</b></th>\n",
        "        </tr>\n",
        "        <tr>\n",
        "        </tr>\n",
        "        <tr>\n",
        "            <td>GitHub</td>\n",
        "            <td><a href=\"https://github.com/muhammadabdullah0303\"><img src=\"https://img.shields.io/badge/GitHub-Profile-blue?style=for-the-badge&logo=github\" alt=\"GitHub\"/></a></td>\n",
        "        </tr>\n",
        "        <tr>\n",
        "            <td>LinkedIn</td>\n",
        "            <td><a href=\"https://www.linkedin.com/in/muhammad-abdullah-6b84b4297/\"><img src=\"https://img.shields.io/badge/LinkedIn-Profile-blue?style=for-the-badge&logo=linkedin\" alt=\"LinkedIn\"/></a></td>\n",
        "        </tr>\n",
        "        <tr>\n",
        "        </tr>\n",
        "        <tr>\n",
        "            <td>Facebook</td>\n",
        "            <td><a href=\"https://web.facebook.com/abd.sentaflexmental\"><img src=\"https://img.shields.io/badge/Facebook-Profile-blue?style=for-the-badge&logo=facebook\" alt=\"Facebook\"/></a></td>\n",
        "        </tr>\n",
        "        <tr>\n",
        "            <td>Gmail</td>\n",
        "            <td><a href=\"mailto:mrabdullah@gmail.com\"><img src=\"https://img.shields.io/badge/Gmail-Contact%20Me-red?style=for-the-badge&logo=gmail\" alt=\"Gmail\"/></a></td>\n",
        "        </tr>\n",
        "    </table>\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "FpuaVWwAthlA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <p style=\"font-family:newtimeroman;font-size:150%;text-align:center;color:#8b4513;\">Dataset Used in This Project Will be IMBD Movies Reviews</p>"
      ],
      "metadata": {
        "id": "tIDnm36ythlB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Basis Libraries\n",
        "import pandas as pd\n",
        "df = pd.read_csv('archive/sentiment_tweets3.csv')\n",
        "# rename column\n",
        "df.rename(columns = {'label (depression result)':'Sentiment'}, inplace = True)\n",
        "df.rename(columns = {'message to examine':'review'}, inplace = True)\n",
        "# Drop Index Column\n",
        "df.drop('Index',axis=1,inplace=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-08T21:08:08.71031Z",
          "iopub.status.busy": "2021-12-08T21:08:08.709642Z",
          "iopub.status.idle": "2021-12-08T21:08:10.561228Z",
          "shell.execute_reply": "2021-12-08T21:08:10.560402Z",
          "shell.execute_reply.started": "2021-12-08T21:08:08.710274Z"
        },
        "trusted": true,
        "id": "X3qbGgNkthlB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Head\n",
        "df.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-08T10:21:20.441483Z",
          "iopub.status.busy": "2021-12-08T10:21:20.441182Z",
          "iopub.status.idle": "2021-12-08T10:21:20.447118Z",
          "shell.execute_reply": "2021-12-08T10:21:20.446333Z",
          "shell.execute_reply.started": "2021-12-08T10:21:20.441438Z"
        },
        "trusted": true,
        "id": "ggcbzxIfthlD",
        "outputId": "082ae70e-4925-4549-8360-de8a8b0485fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 10,
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>just had a real good moment. i missssssssss hi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>is reading manga  http://plurk.com/p/mzp1e</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@comeagainjen http://twitpic.com/2y2lx - http:...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@lapcat Need to send 'em to my accountant tomo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ADD ME ON MYSPACE!!!  myspace.com/LookThunder</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review  Sentiment\n",
              "0  just had a real good moment. i missssssssss hi...          0\n",
              "1         is reading manga  http://plurk.com/p/mzp1e          0\n",
              "2  @comeagainjen http://twitpic.com/2y2lx - http:...          0\n",
              "3  @lapcat Need to send 'em to my accountant tomo...          0\n",
              "4      ADD ME ON MYSPACE!!!  myspace.com/LookThunder          0"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <p style=\"font-family:newtimeroman;font-size:150%;text-align:center;color:#8b4513;\">1. LoweCasing Text</p>\n",
        "\n",
        "\n",
        "***Lowercasing text in NLP preprocessing involves converting all letters in a text to lowercase. This step is essential for standardizing text data because it treats words with different cases (e.g., \"Word\" and \"word\") as the same, reducing vocabulary size and improving model efficiency. It ensures consistency in word representations, making it easier for algorithms to recognize patterns and associations. For example, \"The\" and \"the\" are treated as identical after lowercasing. This normalization simplifies subsequent processing steps, such as tokenization and feature extraction, leading to more accurate and robust NLP models.***\n"
      ],
      "metadata": {
        "id": "xCYAN1rathlE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pick any random Review\n",
        "df['review'][3]"
      ],
      "metadata": {
        "id": "5r8LoBdGthlE",
        "outputId": "769c9eb1-f46e-4c48-8a97-7f33b72b1271"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 13,
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"@lapcat Need to send 'em to my accountant tomorrow. Oddly, I wasn't even referring to my taxes. Those are supporting evidence, though. \""
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***if we have a Single Text or Sentence we can Lowercase it by using lower() func of Python.***"
      ],
      "metadata": {
        "id": "dy9hKN7LthlF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lower Casing the review\n",
        "df['review'][3].lower()"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-08T10:21:00.750114Z",
          "iopub.status.busy": "2021-12-08T10:21:00.749847Z",
          "iopub.status.idle": "2021-12-08T10:21:00.758994Z",
          "shell.execute_reply": "2021-12-08T10:21:00.758482Z",
          "shell.execute_reply.started": "2021-12-08T10:21:00.750086Z"
        },
        "trusted": true,
        "id": "PbKn2w9NthlF",
        "outputId": "db01f160-57fb-4715-da55-086da5b94c97"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 14,
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"@lapcat need to send 'em to my accountant tomorrow. oddly, i wasn't even referring to my taxes. those are supporting evidence, though. \""
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***We can also Lowercase the Whole Corpus by using lower() function of Python.***"
      ],
      "metadata": {
        "id": "tJYmjOxjthlF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['review'] = df['review'].str.lower()\n",
        "df.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-08T10:22:00.387349Z",
          "iopub.status.busy": "2021-12-08T10:22:00.387082Z",
          "iopub.status.idle": "2021-12-08T10:22:00.553846Z",
          "shell.execute_reply": "2021-12-08T10:22:00.553067Z",
          "shell.execute_reply.started": "2021-12-08T10:22:00.38732Z"
        },
        "trusted": true,
        "id": "4aVcppvVthlF",
        "outputId": "411da7c3-bece-421b-b7ff-cb19f26546ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 15,
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>just had a real good moment. i missssssssss hi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>is reading manga  http://plurk.com/p/mzp1e</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@comeagainjen http://twitpic.com/2y2lx - http:...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@lapcat need to send 'em to my accountant tomo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>add me on myspace!!!  myspace.com/lookthunder</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review  Sentiment\n",
              "0  just had a real good moment. i missssssssss hi...          0\n",
              "1         is reading manga  http://plurk.com/p/mzp1e          0\n",
              "2  @comeagainjen http://twitpic.com/2y2lx - http:...          0\n",
              "3  @lapcat need to send 'em to my accountant tomo...          0\n",
              "4      add me on myspace!!!  myspace.com/lookthunder          0"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Now we see all the sentences in the corpus are in lowercase.***"
      ],
      "metadata": {
        "id": "iOEUzmPvthlF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <p style=\"font-family:newtimeroman;font-size:150%;text-align:center;color:#8b4513;\">2. Remove HTML Tags</p>\n",
        "\n",
        "\n",
        "***Removing HTML tags is an essential step in NLP text preprocessing to ensure that only meaningful textual content is analyzed. HTML tags contain formatting information and metadata irrelevant to linguistic analysis. Including these tags can introduce noise and distort the analysis results. Removing HTML tags helps to extract pure textual data, making it easier to focus on the actual content of the text. This step is particularly crucial when dealing with web data or documents containing HTML markup, as it ensures that the extracted text accurately represents the intended linguistic information for NLP tasks.***"
      ],
      "metadata": {
        "id": "jYiHX8TlthlG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***We can simply remove HTML tags by using the Regular Expressions.***"
      ],
      "metadata": {
        "id": "532OsQUPthlG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Regular Expression\n",
        "import re\n",
        "\n",
        "# Function to remove HTML Tags\n",
        "def remove_html_tags(text):\n",
        "    pattern = re.compile('<.*?>')\n",
        "    return pattern.sub(r'', text)"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-08T10:37:17.260075Z",
          "iopub.status.busy": "2021-12-08T10:37:17.259698Z",
          "iopub.status.idle": "2021-12-08T10:37:17.265673Z",
          "shell.execute_reply": "2021-12-08T10:37:17.264763Z",
          "shell.execute_reply.started": "2021-12-08T10:37:17.260041Z"
        },
        "trusted": true,
        "id": "sTxQ0hhKthlG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Suppose we have a text Which Contains HTML Tags\n",
        "text = \"<html><body><p> Movie 1</p><p> Actor - Aamir Khan</p><p> Click here to <a href='http://google.com'>download</a></p></body></html>\"\n",
        "text"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-08T10:37:39.77982Z",
          "iopub.status.busy": "2021-12-08T10:37:39.779507Z",
          "iopub.status.idle": "2021-12-08T10:37:39.784085Z",
          "shell.execute_reply": "2021-12-08T10:37:39.783217Z",
          "shell.execute_reply.started": "2021-12-08T10:37:39.779785Z"
        },
        "trusted": true,
        "id": "uHZCovemthlG",
        "outputId": "0c8961dc-a952-45ea-f239-24d97d26f7f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 18,
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"<html><body><p> Movie 1</p><p> Actor - Aamir Khan</p><p> Click here to <a href='http://google.com'>download</a></p></body></html>\""
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply Function to Remove HTML Tags.\n",
        "remove_html_tags(text)"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-08T10:37:48.202652Z",
          "iopub.status.busy": "2021-12-08T10:37:48.202087Z",
          "iopub.status.idle": "2021-12-08T10:37:48.207164Z",
          "shell.execute_reply": "2021-12-08T10:37:48.20662Z",
          "shell.execute_reply.started": "2021-12-08T10:37:48.202617Z"
        },
        "trusted": true,
        "id": "kcBXWhWPthlG",
        "outputId": "f71a7039-0dc5-428b-ee6b-0d0a156d9ca0"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 20,
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Movie 1 Actor - Aamir Khan Click here to download'"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***See How the Code perform well and clean the text from the HTML Tags , We can Also Apply this Function to Whole Corpus.***"
      ],
      "metadata": {
        "id": "KuvNAQ9QthlG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply Function to Remove HTML Tags in our Dataset Colum Review.\n",
        "df['review'] = df['review'].apply(remove_html_tags)"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-08T10:38:52.024348Z",
          "iopub.status.busy": "2021-12-08T10:38:52.023767Z",
          "iopub.status.idle": "2021-12-08T10:38:52.295961Z",
          "shell.execute_reply": "2021-12-08T10:38:52.29476Z",
          "shell.execute_reply.started": "2021-12-08T10:38:52.024306Z"
        },
        "trusted": true,
        "id": "AUk2lYDethlG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <p style=\"font-family:newtimeroman;font-size:150%;text-align:center;color:#8b4513;\">3. Remove URLs</p>\n",
        "\n",
        "***In NLP text preprocessing, removing URLs is essential to eliminate irrelevant information that doesn't contribute to linguistic analysis. URLs contain website addresses, hyperlinks, and other web-specific elements that can skew the analysis and confuse machine learning models. By removing URLs, the focus remains on the textual content relevant to the task at hand, enhancing the accuracy of NLP tasks such as sentiment analysis, text classification, and information extraction. This step streamlines the dataset, reduces noise, and ensures that the model's attention is directed towards meaningful linguistic patterns and structures within the text.***"
      ],
      "metadata": {
        "id": "pIU6x-4MthlG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Here We also Use Regular Expressions to Remove URLs from Text or Whole Corpus.\n",
        "def remove_url(text):\n",
        "    pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
        "    return pattern.sub(r'', text)"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-08T10:49:34.054005Z",
          "iopub.status.busy": "2021-12-08T10:49:34.053704Z",
          "iopub.status.idle": "2021-12-08T10:49:34.058386Z",
          "shell.execute_reply": "2021-12-08T10:49:34.057762Z",
          "shell.execute_reply.started": "2021-12-08T10:49:34.053975Z"
        },
        "trusted": true,
        "id": "5XfPhLaMthlH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Suppose we have the FOllowings Text With URL.\n",
        "text1 = 'Check out my notebook https://www.kaggle.com/campusx/notebook8223fc1abb'\n",
        "text2 = 'Check out my notebook http://www.kaggle.com/campusx/notebook8223fc1abb'\n",
        "text3 = 'Google search here www.google.com'\n",
        "text4 = 'For notebook click https://www.kaggle.com/campusx/notebook8223fc1abb to search check www.google.com'"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-08T10:52:29.758289Z",
          "iopub.status.busy": "2021-12-08T10:52:29.757982Z",
          "iopub.status.idle": "2021-12-08T10:52:29.761928Z",
          "shell.execute_reply": "2021-12-08T10:52:29.761454Z",
          "shell.execute_reply.started": "2021-12-08T10:52:29.758254Z"
        },
        "trusted": true,
        "id": "61ZJihf0thlH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets Remove The URL by Calling Function\n",
        "print(remove_url(text1))\n",
        "print(remove_url(text2))\n",
        "print(remove_url(text3))\n",
        "print(remove_url(text4))"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-08T10:56:31.400818Z",
          "iopub.status.busy": "2021-12-08T10:56:31.400527Z",
          "iopub.status.idle": "2021-12-08T10:56:31.406438Z",
          "shell.execute_reply": "2021-12-08T10:56:31.405521Z",
          "shell.execute_reply.started": "2021-12-08T10:56:31.400787Z"
        },
        "trusted": true,
        "id": "RcGMuMzSthlH",
        "outputId": "2188a846-4d5c-456b-acad-52366d865735"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Check out my notebook \n\nCheck out my notebook \n\nGoogle search here \n\nFor notebook click  to search check \n"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Here How the function beatuifully remove the URLs from the Text . We Can Simply Call this Function on Whole Corpus to Remove URLs.***"
      ],
      "metadata": {
        "id": "sQYAPqXOthlH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <p style=\"font-family:newtimeroman;font-size:150%;text-align:center;color:#8b4513;\">4. Remove Punctuations</p>\n",
        "\n",
        "\n",
        "***Removing punctuation marks is essential in NLP text preprocessing to enhance the accuracy and efficiency of analysis. Punctuation marks like commas, periods, and quotation marks carry little semantic meaning and can introduce noise into the dataset. By removing them, the text becomes cleaner and more uniform, making it easier for machine learning models to extract meaningful features and patterns. Additionally, removing punctuation aids in standardizing the text, ensuring consistency across documents and improving the overall performance of NLP tasks such as sentiment analysis, text classification, and named entity recognition.***"
      ],
      "metadata": {
        "id": "FAgOa0OathlH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# From String we Imorts Punctuation.\n",
        "import string\n",
        "string.punctuation"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-08T11:27:27.985243Z",
          "iopub.status.busy": "2021-12-08T11:27:27.984584Z",
          "iopub.status.idle": "2021-12-08T11:27:27.990753Z",
          "shell.execute_reply": "2021-12-08T11:27:27.989969Z",
          "shell.execute_reply.started": "2021-12-08T11:27:27.985189Z"
        },
        "trusted": true,
        "id": "Mh0FnC6KthlH",
        "outputId": "bbf2ade0-3fc1-4f83-d468-d8ddb8775743"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 26,
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Storing Punctuation in a Variable\n",
        "punc = string.punctuation"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-08T11:12:07.074296Z",
          "iopub.status.busy": "2021-12-08T11:12:07.074027Z",
          "iopub.status.idle": "2021-12-08T11:12:07.077901Z",
          "shell.execute_reply": "2021-12-08T11:12:07.077307Z",
          "shell.execute_reply.started": "2021-12-08T11:12:07.074267Z"
        },
        "trusted": true,
        "id": "WVTCSth6thlH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The code defines a function, remove_punc1, that takes a text input and removes all punctuation characters from it using\n",
        "# the translate method with a translation table created by str.maketrans. This function effectively cleanses the text of punctuation symbols.\n",
        "def remove_punc(text):\n",
        "    return text.translate(str.maketrans('', '', punc))"
      ],
      "metadata": {
        "id": "t2rumV2LthlH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Text With Punctuation.\n",
        "text = \"The quick brown fox jumps over the lazy dog. However, the dog doesn't seem impressed! Oh no, it just yawned. How disappointing! Maybe a squirrel would elicit a reaction. Alas, the fox is out of luck.\"\n",
        "text"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-08T11:25:11.160928Z",
          "iopub.status.busy": "2021-12-08T11:25:11.160622Z",
          "iopub.status.idle": "2021-12-08T11:25:11.16429Z",
          "shell.execute_reply": "2021-12-08T11:25:11.163672Z",
          "shell.execute_reply.started": "2021-12-08T11:25:11.160893Z"
        },
        "trusted": true,
        "id": "qkspr05IthlI",
        "outputId": "8cf4261c-9f12-4030-de86-cfaf68fd42c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 29,
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"The quick brown fox jumps over the lazy dog. However, the dog doesn't seem impressed! Oh no, it just yawned. How disappointing! Maybe a squirrel would elicit a reaction. Alas, the fox is out of luck.\""
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Punctuation.\n",
        "remove_punc(text)"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-08T11:48:36.142326Z",
          "iopub.status.busy": "2021-12-08T11:48:36.141657Z",
          "iopub.status.idle": "2021-12-08T11:48:36.147256Z",
          "shell.execute_reply": "2021-12-08T11:48:36.14647Z",
          "shell.execute_reply.started": "2021-12-08T11:48:36.142291Z"
        },
        "trusted": true,
        "id": "3djy0BxSthlI",
        "outputId": "3c6c7903-851d-4be4-d9fe-a098e6562347"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 31,
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The quick brown fox jumps over the lazy dog However the dog doesnt seem impressed Oh no it just yawned How disappointing Maybe a squirrel would elicit a reaction Alas the fox is out of luck'"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Hence the function removes the punctuations from the text and we can also use this function to remove the punctuations from the corpus.***"
      ],
      "metadata": {
        "id": "ppB0Wl5UthlI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exmaple on whole Dataset.\n",
        "print(df['review'][9])\n",
        "\n",
        "# Remove Punctuation\n",
        "remove_punc(df['review'][9])"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-08T11:30:35.293558Z",
          "iopub.status.busy": "2021-12-08T11:30:35.292632Z",
          "iopub.status.idle": "2021-12-08T11:30:35.299402Z",
          "shell.execute_reply": "2021-12-08T11:30:35.298461Z",
          "shell.execute_reply.started": "2021-12-08T11:30:35.293506Z"
        },
        "trusted": true,
        "id": "5X4fPPpXthlJ",
        "outputId": "a750c392-ac6a-4346-d487-9bf42ea2ea16"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "@dananner night, darlin'!  sweet dreams to you \n"
        },
        {
          "execution_count": 36,
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'dananner night darlin  sweet dreams to you '"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <p style=\"font-family:newtimeroman;font-size:150%;text-align:center;color:#8b4513;\">5. Handling ChatWords</p>\n",
        "\n",
        "\n",
        "***Handling ChatWords, also known as internet slang or informal language used in online communication, is important in NLP text preprocessing to ensure accurate analysis and understanding of text data. By converting ChatWords into their standard English equivalents or formal language equivalents, NLP models can effectively interpret the meaning of the text. This preprocessing step helps in maintaining consistency, improving the quality of input data, and enhancing the performance of NLP tasks such as sentiment analysis, chatbots, and information retrieval systems. Ultimately, handling ChatWords ensures better comprehension and more reliable results in NLP applications.***"
      ],
      "metadata": {
        "id": "gbfObdV1thlJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Here Come ChatWords Which i Get from a Github Repository\n",
        "# Repository Link : https://github.com/rishabhverma17/sms_slang_translator/blob/master/slang.txt\n",
        "chat_words = {\n",
        "    \"AFAIK\": \"As Far As I Know\",\n",
        "    \"AFK\": \"Away From Keyboard\",\n",
        "    \"ASAP\": \"As Soon As Possible\",\n",
        "    \"ATK\": \"At The Keyboard\",\n",
        "    \"ATM\": \"At The Moment\",\n",
        "    \"A3\": \"Anytime, Anywhere, Anyplace\",\n",
        "    \"BAK\": \"Back At Keyboard\",\n",
        "    \"BBL\": \"Be Back Later\",\n",
        "    \"BBS\": \"Be Back Soon\",\n",
        "    \"BFN\": \"Bye For Now\",\n",
        "    \"B4N\": \"Bye For Now\",\n",
        "    \"BRB\": \"Be Right Back\",\n",
        "    \"BRT\": \"Be Right There\",\n",
        "    \"BTW\": \"By The Way\",\n",
        "    \"B4\": \"Before\",\n",
        "    \"B4N\": \"Bye For Now\",\n",
        "    \"CU\": \"See You\",\n",
        "    \"CUL8R\": \"See You Later\",\n",
        "    \"CYA\": \"See You\",\n",
        "    \"FAQ\": \"Frequently Asked Questions\",\n",
        "    \"FC\": \"Fingers Crossed\",\n",
        "    \"FWIW\": \"For What It's Worth\",\n",
        "    \"FYI\": \"For Your Information\",\n",
        "    \"GAL\": \"Get A Life\",\n",
        "    \"GG\": \"Good Game\",\n",
        "    \"GN\": \"Good Night\",\n",
        "    \"GMTA\": \"Great Minds Think Alike\",\n",
        "    \"GR8\": \"Great!\",\n",
        "    \"G9\": \"Genius\",\n",
        "    \"IC\": \"I See\",\n",
        "    \"ICQ\": \"I Seek you (also a chat program)\",\n",
        "    \"ILU\": \"ILU: I Love You\",\n",
        "    \"IMHO\": \"In My Honest/Humble Opinion\",\n",
        "    \"IMO\": \"In My Opinion\",\n",
        "    \"IOW\": \"In Other Words\",\n",
        "    \"IRL\": \"In Real Life\",\n",
        "    \"KISS\": \"Keep It Simple, Stupid\",\n",
        "    \"LDR\": \"Long Distance Relationship\",\n",
        "    \"LMAO\": \"Laugh My A.. Off\",\n",
        "    \"LOL\": \"Laughing Out Loud\",\n",
        "    \"LTNS\": \"Long Time No See\",\n",
        "    \"L8R\": \"Later\",\n",
        "    \"MTE\": \"My Thoughts Exactly\",\n",
        "    \"M8\": \"Mate\",\n",
        "    \"NRN\": \"No Reply Necessary\",\n",
        "    \"OIC\": \"Oh I See\",\n",
        "    \"PITA\": \"Pain In The A..\",\n",
        "    \"PRT\": \"Party\",\n",
        "    \"PRW\": \"Parents Are Watching\",\n",
        "    \"QPSA?\": \"Que Pasa?\",\n",
        "    \"ROFL\": \"Rolling On The Floor Laughing\",\n",
        "    \"ROFLOL\": \"Rolling On The Floor Laughing Out Loud\",\n",
        "    \"ROTFLMAO\": \"Rolling On The Floor Laughing My A.. Off\",\n",
        "    \"SK8\": \"Skate\",\n",
        "    \"STATS\": \"Your sex and age\",\n",
        "    \"ASL\": \"Age, Sex, Location\",\n",
        "    \"THX\": \"Thank You\",\n",
        "    \"TTFN\": \"Ta-Ta For Now!\",\n",
        "    \"TTYL\": \"Talk To You Later\",\n",
        "    \"U\": \"You\",\n",
        "    \"U2\": \"You Too\",\n",
        "    \"U4E\": \"Yours For Ever\",\n",
        "    \"WB\": \"Welcome Back\",\n",
        "    \"WTF\": \"What The F...\",\n",
        "    \"WTG\": \"Way To Go!\",\n",
        "    \"WUF\": \"Where Are You From?\",\n",
        "    \"W8\": \"Wait...\",\n",
        "    \"7K\": \"Sick:-D Laugher\",\n",
        "    \"TFW\": \"That feeling when\",\n",
        "    \"MFW\": \"My face when\",\n",
        "    \"MRW\": \"My reaction when\",\n",
        "    \"IFYP\": \"I feel your pain\",\n",
        "    \"TNTL\": \"Trying not to laugh\",\n",
        "    \"JK\": \"Just kidding\",\n",
        "    \"IDC\": \"I don't care\",\n",
        "    \"ILY\": \"I love you\",\n",
        "    \"IMU\": \"I miss you\",\n",
        "    \"ADIH\": \"Another day in hell\",\n",
        "    \"ZZZ\": \"Sleeping, bored, tired\",\n",
        "    \"WYWH\": \"Wish you were here\",\n",
        "    \"TIME\": \"Tears in my eyes\",\n",
        "    \"BAE\": \"Before anyone else\",\n",
        "    \"FIMH\": \"Forever in my heart\",\n",
        "    \"BSAAW\": \"Big smile and a wink\",\n",
        "    \"BWL\": \"Bursting with laughter\",\n",
        "    \"BFF\": \"Best friends forever\",\n",
        "    \"CSL\": \"Can't stop laughing\"\n",
        "}\n"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-08T20:20:03.604596Z",
          "iopub.status.busy": "2021-12-08T20:20:03.604312Z",
          "iopub.status.idle": "2021-12-08T20:20:03.612302Z",
          "shell.execute_reply": "2021-12-08T20:20:03.611428Z",
          "shell.execute_reply.started": "2021-12-08T20:20:03.604568Z"
        },
        "trusted": true,
        "id": "gVIE_F90thlJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***The code defines a function, chat_conversion, that replaces text with their corresponding chat acronyms from a predefined dictionary. It iterates through each word in the input text, checks if it exists in the dictionary, and replaces it if found. The modified text is then returned.***"
      ],
      "metadata": {
        "id": "5teCj3IithlJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function\n",
        "def chat_conversion(text):\n",
        "    new_text = []\n",
        "    for i in text.split():\n",
        "        if i.upper() in chat_words:\n",
        "            new_text.append(chat_words[i.upper()])\n",
        "        else:\n",
        "            new_text.append(i)\n",
        "    return \" \".join(new_text)"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-08T20:22:14.393841Z",
          "iopub.status.busy": "2021-12-08T20:22:14.393112Z",
          "iopub.status.idle": "2021-12-08T20:22:14.398492Z",
          "shell.execute_reply": "2021-12-08T20:22:14.397611Z",
          "shell.execute_reply.started": "2021-12-08T20:22:14.393808Z"
        },
        "trusted": true,
        "id": "80JVaNJjthlK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Text\n",
        "text = 'IMHO he is the best'\n",
        "text1 = 'FYI Islamabad is the capital of Pakistan'\n",
        "# Calling function\n",
        "print(chat_conversion(text))\n",
        "print(chat_conversion(text1))"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-08T20:27:43.943973Z",
          "iopub.status.busy": "2021-12-08T20:27:43.943069Z",
          "iopub.status.idle": "2021-12-08T20:27:43.949927Z",
          "shell.execute_reply": "2021-12-08T20:27:43.948991Z",
          "shell.execute_reply.started": "2021-12-08T20:27:43.94393Z"
        },
        "trusted": true,
        "id": "EXkc6vehthlQ",
        "outputId": "ffad19de-ab92-4c4a-ea74-10061847de4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "In My Honest/Humble Opinion he is the best\n\nFor Your Information Islamabad is the capital of Pakistan\n"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Well this is how we Handle ChatWords in Our Data Simple u have to call the above Function.***"
      ],
      "metadata": {
        "id": "-AhWaC7zthlR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <p style=\"font-family:newtimeroman;font-size:150%;text-align:center;color:#8b4513;\">6. Spelling Correction</p>\n",
        "\n",
        "\n",
        "***Spelling correction is a crucial aspect of NLP text preprocessing to enhance data quality and improve model performance. It addresses errors in text caused by typographical mistakes, irregularities, or variations in spelling. Correcting spelling errors ensures consistency and accuracy in the dataset, reducing ambiguity and improving the reliability of NLP tasks like sentiment analysis, machine translation, and information retrieval. By standardizing spelling across the dataset, models can better understand and process text, leading to more precise and reliable results in natural language processing applications.***"
      ],
      "metadata": {
        "id": "hOX_StNDthlR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import this Library to Handle the Spelling Issue.\n",
        "from textblob import TextBlob"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-08T20:43:56.991858Z",
          "iopub.status.busy": "2021-12-08T20:43:56.99156Z",
          "iopub.status.idle": "2021-12-08T20:43:58.636292Z",
          "shell.execute_reply": "2021-12-08T20:43:58.635444Z",
          "shell.execute_reply.started": "2021-12-08T20:43:56.991826Z"
        },
        "trusted": true,
        "id": "ZAC6-5CIthlS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Incorrect text\n",
        "incorrect_text = 'ceertain conditionas duriing seveal ggenerations aree moodified in the saame maner.'\n",
        "print(incorrect_text)\n",
        "# Text 2\n",
        "incorrect_text2 = 'The cat sat on the cuchion. while plyaiing'\n",
        "# Calling function\n",
        "textBlb = TextBlob(incorrect_text)\n",
        "textBlb1 = TextBlob(incorrect_text2)\n",
        "# Corrected Text\n",
        "print(textBlb.correct().string)\n",
        "print(incorrect_text2)\n",
        "print(textBlb1.correct().string)"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-08T20:45:03.889288Z",
          "iopub.status.busy": "2021-12-08T20:45:03.888211Z",
          "iopub.status.idle": "2021-12-08T20:45:03.901265Z",
          "shell.execute_reply": "2021-12-08T20:45:03.900308Z",
          "shell.execute_reply.started": "2021-12-08T20:45:03.889239Z"
        },
        "trusted": true,
        "id": "32ZYUKdWthlS",
        "outputId": "c8370e69-811b-4a1a-af3e-1f82c319f935"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "ceertain conditionas duriing seveal ggenerations aree moodified in the saame maner.\n\ncertain conditions during several generations are modified in the same manner.\n\nThe cat sat on the cuchion. while plyaiing\n\nThe cat sat on the cushion. while playing\n"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Well The Library is Doing Great Job and Handling the Spelling Mistakes , Well u can Use the same Process to Handle the Full corpus.***"
      ],
      "metadata": {
        "id": "KROdJyiythlS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <p style=\"font-family:newtimeroman;font-size:150%;text-align:center;color:#8b4513;\">7. Handling StopWords</p>\n",
        "\n",
        "***In NLP text preprocessing, removing stop words is crucial to enhance the quality and efficiency of analysis. Stop words are common words like \"the,\" \"is,\" and \"and,\" which appear frequently in text but carry little semantic meaning. By eliminating stop words, we reduce noise in the data, decrease the dimensionality of the dataset, and improve the accuracy of NLP tasks such as sentiment analysis, topic modeling, and text classification. This process streamlines the analysis by focusing on the significant words that carry more meaningful information, leading to better model performance and interpretation of results.***"
      ],
      "metadata": {
        "id": "oynxAJznthlS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We use NLTK library to remove Stopwords.\n",
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-08T21:01:00.674241Z",
          "iopub.status.busy": "2021-12-08T21:01:00.673954Z",
          "iopub.status.idle": "2021-12-08T21:01:00.678455Z",
          "shell.execute_reply": "2021-12-08T21:01:00.677834Z",
          "shell.execute_reply.started": "2021-12-08T21:01:00.67421Z"
        },
        "trusted": true,
        "id": "_UNgxYlqthlS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Here we can see all the stopwords in English.However we can chose different Languages also like spanish etc.\n",
        "stopword = stopwords.words('english')"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-08T21:51:03.688191Z",
          "iopub.status.busy": "2021-12-08T21:51:03.687894Z",
          "iopub.status.idle": "2021-12-08T21:51:03.70028Z",
          "shell.execute_reply": "2021-12-08T21:51:03.698834Z",
          "shell.execute_reply.started": "2021-12-08T21:51:03.688159Z"
        },
        "trusted": true,
        "id": "W0eaIj49thlU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***The code defines a function, remove_stopwords, which removes stopwords from a given text. It iterates through each word in the text, checks if it is a stopword, and appends it to a new list if it is not. Then, it clears the original list, returns the modified text.***"
      ],
      "metadata": {
        "id": "Re6NHvzSthlU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function\n",
        "def remove_stopwords(text):\n",
        "    new_text = []\n",
        "\n",
        "    for word in text.split():\n",
        "        if word in stopword:\n",
        "            new_text.append('')\n",
        "        else:\n",
        "            new_text.append(word)\n",
        "    x = new_text[:]\n",
        "    new_text.clear()\n",
        "    return \" \".join(x)"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-08T21:11:12.348251Z",
          "iopub.status.busy": "2021-12-08T21:11:12.347842Z",
          "iopub.status.idle": "2021-12-08T21:11:12.354127Z",
          "shell.execute_reply": "2021-12-08T21:11:12.353513Z",
          "shell.execute_reply.started": "2021-12-08T21:11:12.34821Z"
        },
        "trusted": true,
        "id": "cjRPIb5XthlU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Text\n",
        "text = 'probably my all-time favorite movie, a story of selflessness, sacrifice and dedication to a noble cause, but it\\'s not preachy or boring. it just never gets old, despite my having seen it some 15 or more times'\n",
        "print(f'Text With Stop Words :{text}')\n",
        "# Calling Function\n",
        "remove_stopwords(text)"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-08T21:11:13.833512Z",
          "iopub.status.busy": "2021-12-08T21:11:13.833222Z",
          "iopub.status.idle": "2021-12-08T21:11:13.844653Z",
          "shell.execute_reply": "2021-12-08T21:11:13.843718Z",
          "shell.execute_reply.started": "2021-12-08T21:11:13.833484Z"
        },
        "trusted": true,
        "id": "BKdchURmthlU",
        "outputId": "76670d95-2641-45d3-a543-f786ac97669a"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Text With Stop Words :probably my all-time favorite movie, a story of selflessness, sacrifice and dedication to a noble cause, but it's not preachy or boring. it just never gets old, despite my having seen it some 15 or more times\n"
        },
        {
          "execution_count": 61,
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'probably  all-time favorite movie,  story  selflessness, sacrifice  dedication   noble cause,    preachy  boring.   never gets old, despite   seen   15   times'"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We can Apply the same Function on Whole Corpus also\n",
        "df['review'].apply(remove_stopwords)"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-08T21:11:21.644149Z",
          "iopub.status.busy": "2021-12-08T21:11:21.643717Z",
          "iopub.status.idle": "2021-12-08T21:32:50.295058Z",
          "shell.execute_reply": "2021-12-08T21:32:50.294211Z",
          "shell.execute_reply.started": "2021-12-08T21:11:21.644112Z"
        },
        "trusted": true,
        "id": "dC5pDMR2thlV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Well This the function use to handle stopwords in Text.***"
      ],
      "metadata": {
        "id": "FJuyJr_CthlV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <p style=\"font-family:newtimeroman;font-size:150%;text-align:center;color:#8b4513;\">8. Handling Emojies</p>\n",
        "\n",
        "\n",
        "***Handling emojis in NLP text preprocessing is essential for several reasons. Emojis convey valuable information about sentiment, emotion, and context in text data, especially in informal communication channels like social media. However, they pose challenges for NLP algorithms due to their non-textual nature. Preprocessing involves converting emojis into meaningful representations, such as replacing them with textual descriptions or mapping them to specific sentiment categories. By handling emojis effectively, NLP models can accurately interpret and analyze text data, leading to improved performance in sentiment analysis, emotion detection, and other NLP tasks.***"
      ],
      "metadata": {
        "id": "3XvHnFgithlV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***8.1 Simply Remove Emojis***"
      ],
      "metadata": {
        "id": "J2qjCsCQthlV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***The code defines a function, remove_emoji, which uses a regular expression to match and remove all emojis from a given text string. It targets various Unicode ranges corresponding to different categories of emojis and replaces them with an empty string, effectively removing them from the text.***"
      ],
      "metadata": {
        "id": "3p8jL9XethlV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Again Here we use The Regular Expressions to Remove the Emojies from Text or Whole Corpus.\n",
        "def remove_emoji(text):\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                           u\"\\U00002702-\\U000027B0\"\n",
        "                           u\"\\U000024C2-\\U0001F251\"\n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "    return emoji_pattern.sub(r'', text)"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-09T06:36:47.342491Z",
          "iopub.status.busy": "2021-12-09T06:36:47.342185Z",
          "iopub.status.idle": "2021-12-09T06:36:47.347779Z",
          "shell.execute_reply": "2021-12-09T06:36:47.34681Z",
          "shell.execute_reply.started": "2021-12-09T06:36:47.342459Z"
        },
        "trusted": true,
        "id": "vHFBRaVnthlV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Texts\n",
        "text = \"Loved the movie. It was \"\n",
        "text1 = 'Python is '\n",
        "print(text ,'\\n', text1)\n",
        "\n",
        "# Remove Emojies using Fucntion\n",
        "print(remove_emoji(text))\n",
        "remove_emoji(text1)"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-09T06:41:39.472106Z",
          "iopub.status.busy": "2021-12-09T06:41:39.47184Z",
          "iopub.status.idle": "2021-12-09T06:41:39.478264Z",
          "shell.execute_reply": "2021-12-09T06:41:39.477363Z",
          "shell.execute_reply.started": "2021-12-09T06:41:39.472077Z"
        },
        "trusted": true,
        "id": "suT6dtWVthlW",
        "outputId": "a9e58d4a-a00f-425a-86bf-cfd0e4ba0c94"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Loved the movie. It was  \n\n Python is \n\nLoved the movie. It was \n"
        },
        {
          "execution_count": 66,
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Python is '"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Well the fucntion is removing the emojies easily.***"
      ],
      "metadata": {
        "id": "yy8j0aRythlW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***8.2 Simply Convert Emojis into text***"
      ],
      "metadata": {
        "id": "WBYEdovvthlX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We will USe the Emoji Libray to handle this task\n",
        "# Pip Install emoji\n",
        "import emoji"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-09T06:42:13.319769Z",
          "iopub.status.busy": "2021-12-09T06:42:13.319265Z",
          "iopub.status.idle": "2021-12-09T06:42:13.324864Z",
          "shell.execute_reply": "2021-12-09T06:42:13.324062Z",
          "shell.execute_reply.started": "2021-12-09T06:42:13.319732Z"
        },
        "trusted": true,
        "id": "Dz3IfnHbthlX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calling the Emoji tool Demojize.\n",
        "print(emoji.demojize(text))\n",
        "print(emoji.demojize(text1))"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-09T06:42:20.986779Z",
          "iopub.status.busy": "2021-12-09T06:42:20.986399Z",
          "iopub.status.idle": "2021-12-09T06:42:20.992126Z",
          "shell.execute_reply": "2021-12-09T06:42:20.99145Z",
          "shell.execute_reply.started": "2021-12-09T06:42:20.98675Z"
        },
        "trusted": true,
        "id": "O03g7eXwthlX",
        "outputId": "680e1663-7713-44a1-e633-8032163a483b"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Loved the movie. It was :face_blowing_a_kiss:\n\nPython is :fire:\n"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Well this is the output , and the tool is working best.***"
      ],
      "metadata": {
        "id": "vokVZkIqthlX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <p style=\"font-family:newtimeroman;font-size:150%;text-align:center;color:#8b4513;\">9. Tokenization </p>\n",
        "\n",
        "***Tokenization is a crucial step in NLP text preprocessing where text is segmented into smaller units, typically words or subwords, known as tokens. This process is essential for several reasons. Firstly, it breaks down the text into manageable units for analysis and processing. Secondly, it standardizes the representation of words, enabling consistency in language modeling tasks. Additionally, tokenization forms the basis for feature extraction and modeling in NLP, facilitating tasks such as sentiment analysis, named entity recognition, and machine translation. Overall, tokenization plays a fundamental role in preparing text data for further analysis and modeling in NLP applications.***\n",
        "\n",
        "***We Generally do 2 Type of tokenization 1. Word tokenization 2. Sentence Tokenization***"
      ],
      "metadata": {
        "id": "4vrlrJUZthlX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***9.1 NLTK***\n",
        "***NLTK is a Library used to tokenize text into sentences and words.***"
      ],
      "metadata": {
        "id": "oKch_BEdthlX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraray\n",
        "from nltk.tokenize import word_tokenize,sent_tokenize"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-10T06:02:59.227819Z",
          "iopub.status.busy": "2021-12-10T06:02:59.227483Z",
          "iopub.status.idle": "2021-12-10T06:02:59.837259Z",
          "shell.execute_reply": "2021-12-10T06:02:59.83643Z",
          "shell.execute_reply.started": "2021-12-10T06:02:59.227784Z"
        },
        "trusted": true,
        "id": "Ali9aOibthlX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Text\n",
        "sentence = 'I am going to visit delhi!'\n",
        "# Calling tool\n",
        "word_tokenize(sentence)"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-10T06:03:00.241687Z",
          "iopub.status.busy": "2021-12-10T06:03:00.24139Z",
          "iopub.status.idle": "2021-12-10T06:03:00.264556Z",
          "shell.execute_reply": "2021-12-10T06:03:00.263798Z",
          "shell.execute_reply.started": "2021-12-10T06:03:00.241655Z"
        },
        "trusted": true,
        "id": "xrSe6E5HthlY",
        "outputId": "342d4dc7-1a9b-497a-f2f7-1a0298e393de"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 74,
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I', 'am', 'going', 'to', 'visit', 'delhi', '!']"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Whole text Containing 2 or more Sentences\n",
        "text = \"\"\"Lorem Ipsum is simply dummy text of the printing and typesetting industry?\n",
        "Lorem Ipsum has been the industry's standard dummy text ever since the 1500s,\n",
        "when an unknown printer took a galley of type and scrambled it to make a type specimen book.\"\"\"\n",
        "\n",
        "# Sentence Based Tokenization\n",
        "sent_tokenize(text)"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-10T06:03:00.917544Z",
          "iopub.status.busy": "2021-12-10T06:03:00.915226Z",
          "iopub.status.idle": "2021-12-10T06:03:00.924761Z",
          "shell.execute_reply": "2021-12-10T06:03:00.923887Z",
          "shell.execute_reply.started": "2021-12-10T06:03:00.917502Z"
        },
        "trusted": true,
        "id": "9rm4UiIqthlY",
        "outputId": "fa976601-4463-4b30-cad7-52d99d5083d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 75,
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Lorem Ipsum is simply dummy text of the printing and typesetting industry?',\n",
              " \"Lorem Ipsum has been the industry's standard dummy text ever since the 1500s, \\nwhen an unknown printer took a galley of type and scrambled it to make a type specimen book.\"]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Some Sentences\n",
        "sent5 = 'I have a Ph.D in A.I'\n",
        "sent6 = \"We're here to help! mail us at nks@gmail.com\"\n",
        "sent7 = 'A 5km ride cost $10.50'\n",
        "\n",
        "# Word Tokenize the Sentences\n",
        "print(word_tokenize(sent5))\n",
        "print(word_tokenize(sent6))\n",
        "print(word_tokenize(sent7))"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-10T06:03:01.434559Z",
          "iopub.status.busy": "2021-12-10T06:03:01.43408Z",
          "iopub.status.idle": "2021-12-10T06:03:01.440415Z",
          "shell.execute_reply": "2021-12-10T06:03:01.439625Z",
          "shell.execute_reply.started": "2021-12-10T06:03:01.434523Z"
        },
        "trusted": true,
        "id": "kA0-XvUlthlY",
        "outputId": "f3f0a69b-96f7-43ac-a7b4-95ad408e44bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "['I', 'have', 'a', 'Ph.D', 'in', 'A.I']\n\n['We', \"'re\", 'here', 'to', 'help', '!', 'mail', 'us', 'at', 'nks', '@', 'gmail.com']\n\n['A', '5km', 'ride', 'cost', '$', '10.50']\n"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***NLTK is Performing Well Altough it has some of issue , Like in above text u see it cannot handle the mail. But U can Use it Acording to the data problem***"
      ],
      "metadata": {
        "id": "M2vhUptgthlZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***9.1 Spacy***\n",
        "***Spacy is a Library used to tokenize text into sentences and words.***"
      ],
      "metadata": {
        "id": "areKI1hWthlZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Installation\n",
        "# conda install -c conda-forge spacy\n",
        "# conda install -c conda-forge spacy-model-en_core_web_sm"
      ],
      "metadata": {
        "id": "J9cxgj2wthlZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This code imports the Spacy library and loads the English language model 'en_core_web_sm' for natural language processing.\n",
        "# Pip install spacy library.\n",
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-10T06:03:03.306838Z",
          "iopub.status.busy": "2021-12-10T06:03:03.30623Z",
          "iopub.status.idle": "2021-12-10T06:03:03.978703Z",
          "shell.execute_reply": "2021-12-10T06:03:03.977552Z",
          "shell.execute_reply.started": "2021-12-10T06:03:03.306798Z"
        },
        "trusted": true,
        "id": "zInjgzmdthlZ",
        "outputId": "d7307ace-4cd0-431b-ba62-97eee6bce1f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "d:\\conda3\\envs\\eda_env\\Lib\\site-packages\\spacy\\util.py:910: UserWarning: [W095] Model 'en_core_web_sm' (3.5.0) was trained with spaCy v3.5.0 and may not be 100% compatible with the current version (3.7.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n\n  warnings.warn(warn_msg)\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the Sentences in Words\n",
        "doc1 = nlp(sent5)\n",
        "doc2 = nlp(sent6)\n",
        "doc3 = nlp(sent7)"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-10T06:03:04.01614Z",
          "iopub.status.busy": "2021-12-10T06:03:04.015537Z",
          "iopub.status.idle": "2021-12-10T06:03:04.051271Z",
          "shell.execute_reply": "2021-12-10T06:03:04.050575Z",
          "shell.execute_reply.started": "2021-12-10T06:03:04.01609Z"
        },
        "trusted": true,
        "id": "ud7sgkprthla"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print Token Genrated\n",
        "for token in doc2:\n",
        "    print(token.text)"
      ],
      "metadata": {
        "id": "5HrcG7Zbthla",
        "outputId": "8d62cefc-e13e-4ded-bad9-ad96adf6f85f"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "We\n\n're\n\nhere\n\nto\n\nhelp\n\n!\n\nmail\n\nus\n\nat\n\nnks@gmail.com\n"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***this tool Handle the mail also , so the choice of best tokenizer tool depend on your problem, u can try both and select the best oen.***"
      ],
      "metadata": {
        "id": "B-vtkpCNthla"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <p style=\"font-family:newtimeroman;font-size:150%;text-align:center;color:#8b4513;\">10. Stemming </p>\n",
        "\n",
        "***Stemming is a text preprocessing technique in NLP used to reduce words to their root or base form, known as a stem, by removing suffixes. It helps in simplifying the vocabulary and reducing word variations, thereby improving the efficiency of downstream NLP tasks like information retrieval and sentiment analysis. By converting words to their common root, stemming increases the overlap between related words, enhancing the generalization ability of models.***"
      ],
      "metadata": {
        "id": "e5GxLXfQthla"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import PorterStemmer from NLTK Library\n",
        "from nltk.stem.porter import PorterStemmer"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-10T06:48:34.841005Z",
          "iopub.status.busy": "2021-12-10T06:48:34.840023Z",
          "iopub.status.idle": "2021-12-10T06:48:36.572437Z",
          "shell.execute_reply": "2021-12-10T06:48:36.571736Z",
          "shell.execute_reply.started": "2021-12-10T06:48:34.840888Z"
        },
        "trusted": true,
        "id": "4UB_m9IIthla"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Intilize Stemmer\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "# This Function Will Stem Words\n",
        "def stem_words(text):\n",
        "    return \" \".join([stemmer.stem(word) for word in text.split()])"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-10T06:48:52.93496Z",
          "iopub.status.busy": "2021-12-10T06:48:52.934307Z",
          "iopub.status.idle": "2021-12-10T06:48:52.940919Z",
          "shell.execute_reply": "2021-12-10T06:48:52.940229Z",
          "shell.execute_reply.started": "2021-12-10T06:48:52.934905Z"
        },
        "trusted": true,
        "id": "D3DszjbNthla"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# A single Sentence\n",
        "st = \"walk walks walking walked\"\n",
        "# Calling Function\n",
        "stem_words(st)"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-10T06:49:01.365696Z",
          "iopub.status.busy": "2021-12-10T06:49:01.365203Z",
          "iopub.status.idle": "2021-12-10T06:49:01.37523Z",
          "shell.execute_reply": "2021-12-10T06:49:01.37406Z",
          "shell.execute_reply.started": "2021-12-10T06:49:01.365648Z"
        },
        "trusted": true,
        "id": "H__nZsffthlb",
        "outputId": "58ff76cf-a823-4256-dfba-85c5e79446e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 98,
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'walk walk walk walk'"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"probably my alltime favorite movie a story of selflessness sacrifice and dedication to a noble cause but its not preachy\n",
        "or boring it just never gets old despite my having seen it some 15 or more times in the last 25 years paul lukas performance brings\n",
        " tears to my eyes and bette davis in one of her very few truly sympathetic roles is a delight the kids are as grandma says more like\n",
        " dressedup midgets than children but that only makes them more fun to watch and the mothers slow awakening to whats happening in the\n",
        " world and under her own roof is believable and startling if i had a dozen thumbs theyd all be up for this movie\"\"\"\n",
        "print(text)\n",
        "\n",
        "# Calling Function\n",
        "stem_words(text)"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-09T07:27:21.094383Z",
          "iopub.status.busy": "2021-12-09T07:27:21.094084Z",
          "iopub.status.idle": "2021-12-09T07:27:21.100345Z",
          "shell.execute_reply": "2021-12-09T07:27:21.099323Z",
          "shell.execute_reply.started": "2021-12-09T07:27:21.094352Z"
        },
        "trusted": true,
        "id": "cq8NbbcGthlb",
        "outputId": "c4b8ac84-bc2f-4810-9e49-0fc9aa285048"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "probably my alltime favorite movie a story of selflessness sacrifice and dedication to a noble cause but its not preachy \n\nor boring it just never gets old despite my having seen it some 15 or more times in the last 25 years paul lukas performance brings\n\n tears to my eyes and bette davis in one of her very few truly sympathetic roles is a delight the kids are as grandma says more like \n\n dressedup midgets than children but that only makes them more fun to watch and the mothers slow awakening to whats happening in the \n\n world and under her own roof is believable and startling if i had a dozen thumbs theyd all be up for this movie\n"
        },
        {
          "execution_count": 97,
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'probabl my alltim favorit movi a stori of selfless sacrific and dedic to a nobl caus but it not preachi or bore it just never get old despit my have seen it some 15 or more time in the last 25 year paul luka perform bring tear to my eye and bett davi in one of her veri few truli sympathet role is a delight the kid are as grandma say more like dressedup midget than children but that onli make them more fun to watch and the mother slow awaken to what happen in the world and under her own roof is believ and startl if i had a dozen thumb theyd all be up for thi movi'"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Thats How the Stemming will work***\n",
        "\n",
        "***However, stemming may sometimes result in the production of non-existent or incorrect words, known as stemming errors, which need to be carefully managed to avoid impacting the accuracy of NLP applications.***"
      ],
      "metadata": {
        "id": "mGAtcVtYthlb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <p style=\"font-family:newtimeroman;font-size:150%;text-align:center;color:#8b4513;\">11. Lemmatization </p>\n",
        "\n",
        "\n",
        "***Lemmatization is performed in NLP text preprocessing to reduce words to their base or dictionary form (lemma), enhancing consistency and simplifying analysis. Unlike stemming, which truncates words to their root form without considering meaning, lemmatization ensures that words are transformed to their canonical form, considering their part of speech. This process aids in reducing redundancy, improving text normalization, and enhancing the accuracy of downstream NLP tasks such as sentiment analysis, topic modeling, and information retrieval. Overall, lemmatization contributes to refining text data, facilitating more effective linguistic analysis and machine learning model performance.***"
      ],
      "metadata": {
        "id": "5vjLRNd5thlb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- ***The code imports the WordNetLemmatizer from NLTK library and initializes it.***\n",
        "- ***It defines a sentence and a set of punctuation characters. The sentence is tokenized into words.***\n",
        "- ***Then, it iterates through each word in the sentence, removing punctuation if present.***\n",
        "- ***Next, it lemmatizes each word using the WordNetLemmatizer with a specific part-of-speech tag ('v' for verb).***\n",
        "-  ***Finally, it prints each word along with its corresponding lemma after lemmatization, aligning them in a formatted table.***\n",
        "-  ***This process helps to normalize the words in the sentence by reducing them to their base or dictionary form.***"
      ],
      "metadata": {
        "id": "2vulERNfthlb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We Will Import WordNetLemmatizer from NLTK Library.\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "# Intilize Lemmatizer\n",
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Sentence\n",
        "sentence = \"He was running and eating at same time. He has bad habit of swimming after playing long hours in the Sun.\"\n",
        "\n",
        "# Intilize Punctuation\n",
        "punctuations=\"?:!.,;\"\n",
        "\n",
        "# Tokenize Word\n",
        "sentence_words = nltk.word_tokenize(sentence)\n",
        "\n",
        "# Using a Loop to Remove Punctuations.\n",
        "for word in sentence_words:\n",
        "    if word in punctuations:\n",
        "        sentence_words.remove(word)\n",
        "# Printing Word and Lemmatized Word\n",
        "print(\"{0:20}{1:20}\".format(\"Word\",\"Lemma\"))\n",
        "for word in sentence_words:\n",
        "    print (\"{0:20}{1:20}\".format(word,wordnet_lemmatizer.lemmatize(word,pos='v')))"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-10T07:49:09.331787Z",
          "iopub.status.busy": "2021-12-10T07:49:09.331447Z",
          "iopub.status.idle": "2021-12-10T07:49:09.342678Z",
          "shell.execute_reply": "2021-12-10T07:49:09.341809Z",
          "shell.execute_reply.started": "2021-12-10T07:49:09.331757Z"
        },
        "trusted": true,
        "id": "JVsbQSpIthlb",
        "outputId": "56fb7787-6417-4bfe-91c6-e1536a1c34d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Word                Lemma               \n\nHe                  He                  \n\nwas                 be                  \n\nrunning             run                 \n\nand                 and                 \n\neating              eat                 \n\nat                  at                  \n\nsame                same                \n\ntime                time                \n\nHe                  He                  \n\nhas                 have                \n\nbad                 bad                 \n\nhabit               habit               \n\nof                  of                  \n\nswimming            swim                \n\nafter               after               \n\nplaying             play                \n\nlong                long                \n\nhours               hours               \n\nin                  in                  \n\nthe                 the                 \n\nSun                 Sun                 \n"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Well That's how the Lemmatizer Works.One Best Thing of Lemmatization is That, lemmatization ensures that words are transformed to their canonical form, considering their part of speech.However this Process is Slow***"
      ],
      "metadata": {
        "id": "e8n8sGhIthlc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <p style=\"font-family:newtimeroman;font-size:150%;text-align:center;color:#8b4513;\">. The End</p>\n",
        "\n",
        "***This concludes the basic text preprocessing steps commonly encountered in natural language processing tasks. I hope you have gained a clear understanding of each process. If you have any further questions or queries, feel free to comment below.***\n",
        "\n",
        "***If you found this helpful, please consider upvoting and sharing your feedback. Your support motivates me to continue creating useful content.***\n",
        "\n",
        "***Thank you for your attention and happy learning!***"
      ],
      "metadata": {
        "id": "JmMKL9m_thlc"
      }
    }
  ]
}